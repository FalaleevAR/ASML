{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\Sum}{\\sum\\limits}\n",
    "\\newcommand{\\Int}{\\int\\limits}\n",
    "\\newcommand{\\Intf}{\\int\\limits_{-\\infty}^{+\\infty}}\n",
    "\\newcommand{\\Prod}{\\prod\\limits}\n",
    "\\newcommand{\\Max}{\\max\\limits}\n",
    "\\newcommand{\\Min}{\\min\\limits}\n",
    "\\newcommand{\\Lim}{\\lim\\limits}\n",
    "\\newcommand{\\Var}{\\mathbb{V}}\n",
    "\\newcommand{\\Exp}{\\mathbb{E}}\n",
    "\\newcommand{\\argmax}{\\arg\\max}\n",
    "\\newcommand{\\Cov}{\\mathrm{Cov}}\n",
    "\\newcommand{\\makebold}[1]{\\boldsymbol{#1}}\n",
    "\\newcommand{\\mean}[1]{\\left\\langle #1 \\right\\rangle}\n",
    "\\newcommand{\\Prob}{\\mathcal{P}}\n",
    "\\newcommand{\\eps}{\\varepsilon}\n",
    "\\newcommand{\\loss}{\\mathcal{L}}\n",
    "\\newcommand{\\Llr}{\\mathcal{L}}\n",
    "\\newcommand{\\llr}{\\ell}\n",
    "\\newcommand{\\RR}{\\mathbb{R}}\n",
    "\\newcommand{\\ZZ}{\\mathbb{Z}}\n",
    "\\newcommand{\\NN}{\\mathbb{N}}\n",
    "\\newcommand{\\boldzero}{\\boldsymbol{0}}\n",
    "\\newcommand{\\boldtheta}{\\boldsymbol{\\theta}}\n",
    "\\newcommand{\\boldtau}{\\boldsymbol{\\tau}}\n",
    "\\newcommand{\\boldmu}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\boldeps}{\\boldsymbol{\\eps}}\n",
    "\\newcommand{\\boldx}{\\boldsymbol{x}}\n",
    "\\newcommand{\\boldu}{\\boldsymbol{u}}\n",
    "\\newcommand{\\boldv}{\\boldsymbol{v}}\n",
    "\\newcommand{\\boldw}{\\boldsymbol{w}}\n",
    "\\newcommand{\\boldy}{\\boldsymbol{y}}\n",
    "\\newcommand{\\boldz}{\\boldsymbol{z}}\n",
    "\\newcommand{\\boldp}{\\boldsymbol{p}}\n",
    "\\newcommand{\\boldC}{\\boldsymbol{C}}\n",
    "\\newcommand{\\boldX}{\\boldsymbol{X}}\n",
    "\\newcommand{\\boldY}{\\boldsymbol{Y}}\n",
    "\\newcommand{\\boldZ}{\\boldsymbol{Z}}\n",
    "\\newcommand{\\boldI}{\\boldsymbol{I}}\n",
    "\\newcommand{\\Covariance}{\\boldC}\n",
    "\\newcommand{\\Poisson}{\\mathrm{Poisson}}\n",
    "\\newcommand{\\Uniform}{\\mathrm{Uniform}}\n",
    "\\newcommand{\\Binomial}{\\mathrm{Binomial}}\n",
    "\\newcommand{\\Gammap}{\\mathrm{Gamma}}\n",
    "\\newcommand{\\Normal}{\\mathcal{N}}\n",
    "\\newcommand{\\LogN}{\\mathrm{LogN}}\n",
    "\\newcommand{\\Exponential}{\\mathrm{Exp}}\n",
    "\\newcommand{\\Erlang}{\\mathrm{Erlang}}\n",
    "\\newcommand{\\Cauchy}{C}\n",
    "\\newcommand{\\lf}{\\left\\{}\n",
    "\\newcommand{\\rf}{\\right\\}}\n",
    "\\newcommand{\\lp}{\\left(}\n",
    "\\newcommand{\\rp}{\\right)}\n",
    "\\newcommand{\\ls}{\\left[}\n",
    "\\newcommand{\\rs}{\\right]}\n",
    "\\newcommand{\\lv}{\\left|}\n",
    "\\newcommand{\\rv}{\\right|}\n",
    "\\newcommand{\\Ecdf}[1]{\\hat{F}_n(#1)}\n",
    "\\newcommand{\\boot}{\\mathrm{boot}}\n",
    "\\newcommand{\\bias}{\\mathrm{bias}}\n",
    "\\newcommand{\\se}{\\mathrm{se}}\n",
    "\\newcommand{\\MSE}{\\mathrm{MSE}}\n",
    "\\newcommand{\\qm}{\\mathrm{qm}}\n",
    "\\newcommand{\\as}{\\mathrm{as}}\n",
    "\\newcommand{\\trace}{\\mathrm{trace}}\n",
    "\\newcommand{\\esttheta}{\\hat{\\theta}}\n",
    "\\newcommand{\\estlambda}{\\hat{\\lambda}}\n",
    "\\newcommand{\\estmu}{\\hat{\\mu}}\n",
    "\\newcommand{\\estsigma}{\\hat{\\sigma}}\n",
    "\\newcommand{\\estalpha}{\\hat{\\alpha}}\n",
    "\\newcommand{\\estbeta}{\\hat{\\beta}}\n",
    "\\newcommand{\\estxi}{\\hat{\\xi}}\n",
    "\\newcommand{\\esttau}{\\hat{\\tau}}\n",
    "\\newcommand{\\estpsi}{\\hat{\\psi}}\n",
    "\\newcommand{\\esta}{\\hat{a}}\n",
    "\\newcommand{\\estb}{\\hat{b}}\n",
    "\\newcommand{\\estc}{\\hat{c}}\n",
    "\\newcommand{\\estd}{\\hat{d}}\n",
    "\\newcommand{\\estp}{\\hat{p}}\n",
    "\\newcommand{\\estT}{\\hat{T}}\n",
    "\\newcommand{\\estR}{\\hat{R}}\n",
    "\\newcommand{\\estF}{\\hat{F}}\n",
    "\\newcommand{\\estf}{\\hat{f}}\n",
    "\\newcommand{\\estC}{\\hat{C}}\n",
    "\\newcommand{\\estS}{\\hat{S}}\n",
    "\\newcommand{\\estY}{\\hat{Y}}\n",
    "\\newcommand{\\esty}{\\hat{y}}\n",
    "\\newcommand{\\estVar}{\\hat{\\Var}}\n",
    "\\newcommand{\\estExp}{\\hat{\\Exp}}\n",
    "\\newcommand{\\estSe}{\\hat{\\se}}\n",
    "\\newcommand{\\hata}{\\hat{a}}\n",
    "\\newcommand{\\hatb}{\\hat{b}}\n",
    "\\newcommand{\\hatc}{\\hat{c}}\n",
    "\\newcommand{\\hatd}{\\hat{d}}\n",
    "\\newcommand{\\hatf}{\\hat{f}}\n",
    "\\newcommand{\\hatg}{\\hat{g}}\n",
    "\\newcommand{\\hatk}{\\hat{k}}\n",
    "\\newcommand{\\hatp}{\\hat{p}}\n",
    "\\newcommand{\\hatr}{\\hat{r}}\n",
    "\\newcommand{\\hatt}{\\hat{t}}\n",
    "\\newcommand{\\hatw}{\\hat{w}}\n",
    "\\newcommand{\\haty}{\\hat{y}}\n",
    "\\newcommand{\\hatC}{\\hat{C}}\n",
    "\\newcommand{\\hatF}{\\hat{F}}\n",
    "\\newcommand{\\hatJ}{\\hat{J}}\n",
    "\\newcommand{\\hatK}{\\hat{K}}\n",
    "\\newcommand{\\hatY}{\\hat{Y}}\n",
    "\\newcommand{\\hatsigma}{\\hat{\\sigma}}\n",
    "\\newcommand{\\hatboldw}{\\hat{\\boldw}}\n",
    "\\newcommand{\\tiltau}{\\tilde{\\tau}}\n",
    "\\newcommand{\\tiltheta}{\\tilde{\\theta}}\n",
    "\\newcommand{\\tillambda}{\\tilde{\\lambda}}\n",
    "\\newcommand{\\tilsigma}{\\tilde{\\sigma}}\n",
    "\\newcommand{\\mlexi}{\\xi_{MLE}}\n",
    "\\newcommand{\\RSS}{\\mathrm{RSS}}\n",
    "\\newcommand{\\mletheta}{\\theta_{MLE}}\n",
    "\\newcommand{\\mlelambda}{\\lambda_{MLE}}\n",
    "\\newcommand{\\mlesigma}{\\sigma_{MLE}}\n",
    "\\newcommand{\\mmxi}{\\xi_{MM}}\n",
    "\\newcommand{\\mmtheta}{\\theta_{MM}}\n",
    "\\newcommand{\\mmlambda}{\\lambda_{MM}}\n",
    "\\newcommand{\\mmsigma}{\\sigma_{MM}}\n",
    "\\newcommand{\\mmgamma}{\\gamma_{MM}}\n",
    "\\newcommand{\\xs}[1]{\\boldx^{(#1)}}\n",
    "\\newcommand{\\ys}[1]{\\boldy^{(#1)}}\n",
    "\\newcommand{\\zs}[1]{\\boldz^{(#1)}}\n",
    "\\newcommand{\\Xs}[1]{\\boldX^{(#1)}}\n",
    "\\newcommand{\\Ys}[1]{\\boldY^{(#1)}}\n",
    "\\newcommand{\\Zs}[1]{\\boldZ^{(#1)}}\n",
    "\\newcommand{\\pvalue}{\\text{p-value}}\n",
    "\\newcommand{\\Risk}{\\mathcal{R}}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import copy\n",
    "\n",
    "from scipy import stats\n",
    "from itertools import product\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "from itertools import combinations, product\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "# sklearn\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from sklearn.kernel_ridge import KernelRidge, pairwise_kernels\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.collections import PolyCollection\n",
    "from matplotlib.colors import colorConverter\n",
    "%matplotlib inline\n",
    "\n",
    "titlesize = 24\n",
    "labelsize = 22\n",
    "legendsize = 22\n",
    "xticksize = 18\n",
    "yticksize = xticksize\n",
    "\n",
    "matplotlib.rcParams['legend.markerscale'] = 1.5     # the relative size of legend markers vs. original\n",
    "matplotlib.rcParams['legend.handletextpad'] = 0.5\n",
    "matplotlib.rcParams['legend.labelspacing'] = 0.4    # the vertical space between the legend entries in fraction of fontsize\n",
    "matplotlib.rcParams['legend.borderpad'] = 0.5       # border whitespace in fontsize units\n",
    "matplotlib.rcParams['font.size'] = 12\n",
    "matplotlib.rcParams['font.family'] = 'serif'\n",
    "matplotlib.rcParams['font.serif'] = 'Times New Roman'\n",
    "matplotlib.rcParams['axes.labelsize'] = labelsize\n",
    "matplotlib.rcParams['axes.titlesize'] = titlesize\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 8)\n",
    "\n",
    "matplotlib.rc('xtick', labelsize=xticksize)\n",
    "matplotlib.rc('ytick', labelsize=yticksize)\n",
    "matplotlib.rc('legend', fontsize=legendsize)\n",
    "\n",
    "matplotlib.rc('font', **{'family':'serif'})\n",
    "# matplotlib.rc('text', usetex=True)\n",
    "# matplotlib.rc('text.latex', unicode=True)\n",
    "# matplotlib.rc('text.latex', preamble=r'\\usepackage[utf8]{inputenc}')\n",
    "# matplotlib.rc('text.latex', preamble=r'\\usepackage[english]{babel}')\n",
    "# matplotlib.rc('text.latex', preamble=r'\\usepackage{amsmath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc'></a>\n",
    "# Содержание\n",
    "* [Обусловленность и регуляризация](#conditioning)\n",
    "* [Отбор признаков в модели линейной регрессии](#model_choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conditioning'></a>\n",
    "# Обусловленность и регуляризация [[toc]](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим некоторый сигнал $f \\in \\mathbb{R}^n$. Мы не знаем его реальное значение, т.к. воспринимаем его с помощью некоторого прибора. Прибором в нашей терминологии является линейный оператор $A: \\mathbb{R}^n \\to \\mathbb{R}^n$, влияющий на истинный сигнал $f$ и преобразующий его в воспринимаемое нами предтавление.\n",
    "\n",
    "Т.е. мы видим результат измерений $\\xi = Af + \\nu$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes  = np.array([10.0, 1.0])\n",
    "frequencies = np.array([1. / 32, 1. / 2])\n",
    "periods = 1.0 / frequencies\n",
    "angle_frequencies = 2 * np.pi * frequencies\n",
    "# Signal f dimension.\n",
    "n_points = 256\n",
    "\n",
    "time_start = 0\n",
    "time_end = np.max(periods)\n",
    "t = np.linspace(time_start, time_end, n_points).reshape(-1, 1)\n",
    "time_step = (time_end - time_start) / (n_points - 1)\n",
    "\n",
    "f = np.sum(amplitudes * np.sin(t * angle_frequencies), axis=1)\n",
    "\n",
    "plt.plot(t, f, linewidth=2, color='b')\n",
    "plt.grid(which='both', linestyle='--')\n",
    "plt.xlabel('x')\n",
    "tmp_ = plt.ylabel('sum of sines')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот так выглядит оператор $A$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.eye(n_points)\n",
    "filter_size = 10\n",
    "filter_span = filter_size // 2\n",
    "for i in range(n_points):\n",
    "    A[i, max(i - filter_span, 0): min(i + filter_span + 1, n_points)] = 1\n",
    "A /= filter_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(A)\n",
    "tmp_ = plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем результат измерения сигнала прибором:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.1\n",
    "nu = np.random.normal(0, sigma, f.shape)\n",
    "xi = A.dot(f) + nu\n",
    "\n",
    "plt.plot(xi, label='noisy')\n",
    "plt.plot(f, label='clean')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('signal value')\n",
    "tmp_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка наименьших квадратов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хотелось бы по $\\xi$ построить оценку реального сигнала -- т.е. решить задачу регрессии.\n",
    "\n",
    "MLE оценки в случае нормального шума получены на лекции / семинаре / самостоятельно:\n",
    "$$\n",
    "\\xi = Af + \\nu, \\quad \\nu \\sim \\mathcal{N}(0, \\sigma^2)\\\\\n",
    "\\hat f = \\underbrace{(A^TA)^{-1}A^T}_{R} \\cdot \\xi\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.linalg.inv(A.T.dot(A)).dot(A.T)\n",
    "f_estimate = R.dot(xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xi, label='noisy')\n",
    "plt.plot(f, label='clean')\n",
    "plt.plot(f_estimate, label='estimate')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('signal value')\n",
    "plt.title('Oops...')\n",
    "tmp_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что случилось? Случилось то, что матрица плохо обусловлена и всё сломалось.\n",
    "\n",
    "Можно напрямую вычислить псевдообратную матрицу для $A$: $A^{+} = (A^TA)^{-1}A^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.linalg.pinv(A)\n",
    "f_estimate = R.dot(xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xi, label='noisy')\n",
    "plt.plot(f, label='clean')\n",
    "plt.plot(f_estimate, label='estimate')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('signal value')\n",
    "tmp_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На самом деле, понять, что всё будет плохо, можно было просто взглянув на [число обусловленности](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%BD%D0%BE%D0%B3%D0%BE%D0%BC%D0%B5%D1%80%D0%BD%D0%B0%D1%8F_%D0%BB%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D0%B0%D1%8F_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F#.D0.9F.D1.80.D0.BE.D0.B1.D0.BB.D0.B5.D0.BC.D1.8B) $A$ -- отношение максимального и минимального СЗ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.cond(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление $l_2$ регуляризации\n",
    "Попробуем перед обращением матрицы добавить к её диагонали небольшие числа:\n",
    "$$\n",
    "\\tilde R = (A^TA + \\lambda I)^{-1}A^T\n",
    "$$\n",
    "Тем самым мы надеемся получить невырожденную матрицу, практически не повлияв на её значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change that for some more appropriate value.\n",
    "reg_coeff = 0.001\n",
    "R = np.linalg.inv(A.T.dot(A) + reg_coeff * np.eye(A.shape[0])).dot(A.T)\n",
    "f_estimate = R.dot(xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xi, label='noisy')\n",
    "plt.plot(f, label='clean')\n",
    "plt.plot(f_estimate, label='estimate')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('signal value')\n",
    "tmp_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model_choice'></a>\n",
    "# Линейная регрессии [[toc]](#toc)\n",
    "* [Модель линейной регрессии](#linear_regression_model)\n",
    "* [Необходимый функционал](#model_choice_func)\n",
    "    * [Критерии](#criterions)\n",
    "    * [Классы FullSearch и GreedySearch](#model_search)\n",
    "    * [Функции для визуализации динамики весов](#model_plot)\n",
    "* [Diabetes dataset](#diabetes)\n",
    "* [Prostate dataset](#prostate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='linear_regression_model'></a>\n",
    "## Модель линейной регрессии<sup>[toc](#toc)</sup>\n",
    "Предполагается, что наблюдаемые значения вектора $\\boldx \\in \\RR^d$ (зависимых переменных) и $y \\in \\RR$ (независимой переменной) связаны следующим образом\n",
    "$$\n",
    "y = \\boldx^T\\boldw + \\eps, \\quad \\eps \\sim \\Normal(0, \\sigma^2)\n",
    "$$\n",
    "Или в матричном виде\n",
    "$$\n",
    "\\boldy = \\boldX\\boldw + \\boldeps, \\quad \\boldeps \\sim \\Normal(\\boldzero, \\sigma^2 \\boldI)\n",
    "$$\n",
    "\n",
    "Сумма квадратов невязок (**residual sum of squares**):\n",
    "$$\n",
    "\\RSS(\\boldw) = \\|\\boldX\\boldw - \\boldy\\|_2^2\n",
    "$$\n",
    "\n",
    "В качестве оценки весов $\\boldw$ выбираются веса, минимизирующие значения $\\RSS(\\boldw)$:\n",
    "$$\n",
    "\\RSS(\\boldw) \\rightarrow \\min_{\\boldw}\n",
    "$$\n",
    "Полученая оценка весов $\\hatboldw$ называется OLS-оценкой (Ordinary Least Squares). На предыдущем семинаре для этой оценки получили следующие свойства:\n",
    "\\begin{align*}\n",
    "&\\hatboldw = (\\boldX^T\\boldX)^{-1}\\boldX^T\\boldy\\\\\n",
    "&\\Exp_{\\boldw} \\hatboldw = \\boldw, \\quad \\Cov_{\\boldw}(\\hatboldw) = \\sigma^2(\\boldX^T\\boldX)^{-1}\\\\\n",
    "&\\hatsigma^2 = \\frac{1}{n - d}\\RSS(\\hatboldw),\\quad\\Exp_{\\boldw}\\ls\\RSS(\\hatboldw)\\rs = (n - d)\\sigma^2, \\quad \\Exp_{\\boldw}\\hatsigma^2 = \\sigma^2\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='simple_linear_regression_model'></a>\n",
    "### Простая линейная регрессия<sup>[toc](#toc)</sup>\n",
    "$$\n",
    "y = w_0 x + w_1 + \\eps\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\boldX = \\begin{pmatrix}\n",
    "x_1 &1\\\\\n",
    "x_2 &1\\\\\n",
    "\\vdots &\\vdots \\\\\n",
    "x_N &1\n",
    "\\end{pmatrix},\\quad\n",
    "\\boldw = \\begin{pmatrix}\n",
    "w_0\\\\\n",
    "w_1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Cov \\begin{pmatrix}\n",
    "\\hatw_0\\\\\n",
    "\\hatw_1\n",
    "\\end{pmatrix} =\n",
    "\\sigma^2 (\\boldX^T\\boldX)^{-1} =\n",
    "\\begin{pmatrix}\n",
    "\\sum_i x_i^2 &\\sum_i x_i\\\\\n",
    "\\sum_i x_i   &n\n",
    "\\end{pmatrix}^{-1} = \n",
    " \\sigma^2\n",
    "\\begin{pmatrix}\n",
    "n \\mean{\\boldx^2} & n\\mean{\\boldx}\\\\\n",
    "n \\mean{\\boldx}   & n\n",
    "\\end{pmatrix}^{-1} =\n",
    "\\frac{\\sigma^2}{n\\lp\\mean{\\boldx^2} - \\mean{\\boldx}^2\\rp}\n",
    "\\begin{pmatrix}\n",
    "\\mean{\\boldx^2} & -\\mean{\\boldx}\\\\\n",
    "-\\mean{\\boldx}  & 1\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='linear_regression_p_values'></a>\n",
    "### p-value значений весов<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если $\\boldeps \\sim \\Normal(\\boldzero, \\sigma^2\\boldI)$, то\n",
    "$$\n",
    "\\hatboldw \\sim \\Normal(\\underbrace{(\\boldX^T\\boldX)^{-1}\\boldX^T\\boldy}_{\\boldmu}, \\underbrace{\\sigma^2(\\boldX^T\\boldX)^{-1}}_{\\Sigma})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\boldw = (w_1, \\dots, w_n)^T \\in \\RR^n\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(\\hatw_i) = \\Normal(\\hatw_i; w_i, \\sigma_i^2), \\quad \\sigma_i^2 = \\Covariance_{ii}\n",
    "$$\n",
    "\n",
    "Можем проверить гипотезу $H_0\\colon \\hatw_i = 0$ против альтернативы $H_0\\colon \\hatw_i \\neq 0$. Для этого воспользуемся критерием Вальда:\n",
    "$$\n",
    "W = \\frac{\\hatw_i}{\\sigma_i}, \\qquad \\pvalue = 2\\Phi(-|W|)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='medical_insurance_dataset'></a>\n",
    "## Датасет по медицинской страховке<sup>[toc](#toc)</sup>\n",
    "* [kaggle](https://www.kaggle.com/mirichoi0218/insurance/data)\n",
    "* [github](https://github.com/stedy/Machine-Learning-with-R-datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='medical_insurance_dataset_read'></a>\n",
    "### Описание датасета, считывание данных<sup>[toc](#toc)</sup>\n",
    "* age: age of primary beneficiary\n",
    "* sex: insurance contractor gender, female, male\n",
    "* bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n",
    "* children: Number of children covered by health insurance / Number of dependents\n",
    "* smoker: Smoking\n",
    "* region: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n",
    "* charges: Individual medical costs billed by health insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import os\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = os.path.dirname(os.path.abspath(os.curdir))\n",
    "datasets_dir = os.path.join(repo_dir, 'datasets')\n",
    "dataset_path = os.path.join(datasets_dir, 'insurance', 'insurance.csv')\n",
    "assert os.path.isfile(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(dataset_path)\n",
    "samples_number, features_number = data.shape\n",
    "print('samples_number = {}, featues_number = {}'.format(samples_number, features_number))\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['charges'].values\n",
    "assert y.shape == (samples_number,)\n",
    "\n",
    "features = {}\n",
    "features['age'] = data['age'].values.astype(np.float64).reshape(-1, 1)\n",
    "features['sex'] = (data['sex'] == 'male').values.astype(np.float64).reshape(-1, 1)\n",
    "features['bmi'] = data['bmi'].values.astype(np.float64).reshape(-1, 1)\n",
    "features['children'] = data['children'].values.astype(np.float64).reshape(-1, 1)\n",
    "features['smoker'] = (data['smoker'] == 'yes').values.astype(np.float64).reshape(-1, 1)\n",
    "\n",
    "regions = data['region']\n",
    "regions_ohe = OneHotEncoder(sparse=False)\n",
    "regions_ohe.fit(regions.values.reshape(-1, 1))\n",
    "print(regions_ohe.categories_)\n",
    "features['regions'] = regions_ohe.transform(regions.values.reshape(-1, 1))\n",
    "print(np.sum(features['regions'], axis=0))\n",
    "\n",
    "X = np.hstack([features['age'],\n",
    "               features['sex'],\n",
    "               features['bmi'],\n",
    "               features['children'],\n",
    "               features['smoker'],\n",
    "               features['regions']])\n",
    "print(X.shape, y.shape)\n",
    "X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='insurance_training'></a>\n",
    "### Обучение модели линейной регрессии<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_weights(X, y):\n",
    "    \"\"\"Finds the OLS/MLE weights estimate for multivariate linear regression model\n",
    "\n",
    "    :param X: Matrix (np.ndarray) of shape (N, D) where N is number of objects and D is\n",
    "        dimensionality of an object's feature vector\n",
    "    :param y: Matrix of known dependent variables\n",
    "    \"\"\"\n",
    "    assert X.ndim == 2 and y.ndim == 1\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    return np.linalg.inv(np.dot(X.T, X)).dot(X.T).dot(y)\n",
    "\n",
    "\n",
    "class LinearRegression(object):\n",
    "    def __init__(self, fit_intercept=True):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self._fit_intercept = fit_intercept\n",
    "        self._weights = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        assert False\n",
    "    \n",
    "    def RSS(self, X, y):\n",
    "        assert False\n",
    "\n",
    "    def MSE(self, X, y):\n",
    "        assert False\n",
    "\n",
    "    def predict(self, X):\n",
    "        assert False\n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        assert False\n",
    "    \n",
    "    @property\n",
    "    def sigma2(self):\n",
    "        assert False\n",
    "    \n",
    "    @property\n",
    "    def covariance(self):\n",
    "        assert False\n",
    "    \n",
    "    @property\n",
    "    def variances(self):\n",
    "        assert False\n",
    "    \n",
    "    @property\n",
    "    def p_values(self):\n",
    "        assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='train_sklearn_model'></a>\n",
    "#### Обучение линейной регрессии из sklearn-а<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_regr = linear_model.LinearRegression(fit_intercept=False)\n",
    "lin_regr.fit(X_train, y_train)\n",
    "lin_regr.score(X_train, y_train)\n",
    "lin_regr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='train_self_written_model'></a>\n",
    "#### Обучение самописной линейной регрессии<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_regr = LinearRegression(fit_intercept=False)\n",
    "lin_regr.fit(X_train, y_train)\n",
    "print('weighjts =', lin_regr.weights)\n",
    "print('sigma =', np.sqrt(lin_regr.sigma2))\n",
    "print('weights deviations =', np.sqrt(lin_regr.variances))\n",
    "print('p_values =', np.sqrt(lin_regr.p_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE on train data =', lin_regr.MSE(X_train, y_train))\n",
    "print('MSE on test data = ', lin_regr.MSE(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регуляризация<sup>[toc](#toc)<sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bayesian_regression'></a>\n",
    "## Байесовская регрессия<sup>[toc](#toc)<sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model_choice_func'></a>\n",
    "## Выбор модели/отбор признаков<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $(\\boldX, \\boldy)$ &mdash; обучающая выборка: $\\boldX \\in \\RR^{n\\times d}$, $\\boldy \\in \\RR^n$\n",
    "* $a(\\cdot; \\boldX, \\boldy)$ &mdash; некоторым алгоритм предсказания, построенный по обучающей выборке $(\\boldX,\\boldy)$\n",
    "\n",
    "Пусть известно совместное распределение $F_{\\boldx,y}$.\n",
    "* $r(\\boldx) = \\Exp_{y|\\boldx} (y) = \\Int yp(y|\\boldx)dy$ &mdash; функция регрессии\n",
    "* $a(\\cdot) \\triangleq a(\\cdot;\\boldX,\\boldy)$ &mdash; аппроксимация функции регрессии\n",
    "\n",
    "$$\n",
    "\\Risk(a) = \\Exp_{\\boldX,\\boldy} \\ls \\Exp_{\\boldx,y} (y - a(x;\\boldX,\\boldy))^2 \\rs\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\bar{a}(x) = \\Exp_{\\boldX,\\boldy} \\ls a(\\boldx;\\boldX,\\boldy) \\rs\n",
    "$$\n",
    "\n",
    "Можно показать, что\n",
    "$$\n",
    "\\Risk(a) = \\underbrace{\\Exp_{\\boldx,y} (y - r(\\boldx))^2}_{шум (noise)} +\n",
    "\\underbrace{\\Exp_{\\boldx}(r(\\boldx) - \\bar{a}(\\boldx))^2}_{смещение (bias)} +\n",
    "\\underbrace{\\Exp_{\\boldX,\\boldy}\\Exp_{\\boldx}(a(\\boldx;\\boldX,\\boldy) - \\bar{a}(\\boldx))^2}_{вариация (variance)},\n",
    "$$\n",
    "т.е. **bias variance decomposition**.\n",
    " \n",
    "На практике не знаем $F_{\\boldx,y}$, поэтому нужно уметь оценивать все по самой выборке $(\\boldX,\\boldy)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\tr}{\\mathrm{tr}}$\n",
    "\n",
    "Давайте предположим, что пока что знаем условные распределения $F_{y|\\boldx}$, но не знаем $F_{\\boldx}$. Вместо распределения $F_{\\boldx}$ фактически возьмем э.ф.р. $\\hatF_{\\boldx}$.\n",
    "$$\n",
    "\\Risk(a;\\boldX) = \\frac{1}{n}\\Exp_{\\boldy|\\boldX} \\ls \\Sum_{i = 1}^n \\Exp_{y^*|\\boldx_i}\\lp y^* - a(\\boldx_i; \\boldX, \\boldy)\\rp^2 \\rs\n",
    "$$\n",
    "\n",
    "Теперь частично откажемся от знания распределения $F_{y|\\boldx}$, фактически заменяя его в каждой точке на э.ф.р. $\\hatF_{y|\\boldx}$:\n",
    "$$\n",
    "\\Risk_{\\tr}(a;\\boldX,\\boldy) = \\frac{1}{n} \\Exp_{\\boldy|\\boldX} \\ls \\Sum_{i = 1}^n \\lp y_i - a(\\boldx_i; \\boldX, \\boldy)\\rp^2 \\rs\n",
    "$$\n",
    "\n",
    "* $\\Risk(a;\\boldX)$ &mdash; **ошибка на предсказании**\n",
    "* $\\Risk_{\\tr}(a;\\boldX,\\boldy)$ &mdash; **ошибка на обучении**\n",
    "\n",
    "Естественно ожидать, что\n",
    "$$\\Risk_{\\tr}(a;\\boldX,\\boldy) \\le \\Risk(a;\\boldX)$$\n",
    "Можно показать, что\n",
    "$$\n",
    "\\Risk(a;\\boldX) = \\Risk_{\\tr}(a;\\boldX,\\boldy) + \\frac{2}{n} \\Sum_{i = 1}^n \\Cov_{\\boldy|\\boldX}(a(\\boldx_i), y_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Статистика Mallow $C_p$\n",
    "В случае модели линейной регрессии\n",
    "$$\n",
    "\\boldy = \\boldX\\boldw + \\boldeps, \\quad \\boldX \\in \\RR^{n\\times d}, \\quad \\boldy \\in \\RR^{n}, \\quad \\Exp\\boldeps = \\boldzero, \\quad \\Var \\boldeps = \\sigma^2 \\boldI\n",
    "$$\n",
    "можно показать, что\n",
    "$$\n",
    "\\Risk(a;\\boldX) = \\Risk_{\\tr}(a;\\boldX,\\boldy) + \\frac{2d\\sigma^2}{n}.\n",
    "$$\n",
    "\n",
    "Но распределение $F_{y|\\boldx}$ нам все также неизвестно, поэтому требуется отказтаься и от него\n",
    "\\begin{align}\n",
    "&\\hat{\\Risk}_{\\tr}(a;\\boldX,\\boldy) = \\frac{1}{n}\\Sum_{i=1}^n(a(\\boldx_i;\\boldX,\\boldy) - y_i)^2 = \\frac{1}{n}\\|\\boldX\\hatboldw - \\boldy\\|^2,\\\\\n",
    "&\\hat{\\Risk}(a;\\boldX,\\boldy) = \\hat{\\Risk}_{\\tr}(a;\\boldX,\\boldy) + \\frac{2d\\hatsigma^2}{n},\\\\\n",
    "&\\hatsigma^2 = \\frac{1}{n - d}\\Sum_{i = 1}^n(y_i - a(\\boldx_i;\\boldX,\\boldy)^2)\n",
    "\\end{align}\n",
    "Поэтому\n",
    "$$\n",
    "\\hat{\\Risk}(a;\\boldX,\\boldy) = \\frac{1}{n}\\|\\boldX\\hatboldw - \\boldy\\|^2 + \\frac{2d}{n} \\frac{1}{n - d} \\|\\boldX\\hatboldw - \\boldy\\|_2^2 =\\frac{n + d}{n - d} \\cdot \\frac{1}{n} \\|\\boldX\\hatboldw - \\boldy\\|^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOO-проверка<sup>[toc](#toc)</sup>\n",
    "$$\n",
    "\\hat{\\Risk}(a;\\boldX,\\boldy) = \\frac{1}{n}\\Sum_{i = 1}^n (a(\\boldx_i, \\boldX^{-i}, \\boldy^{-i}))\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\Risk}(a;\\boldX,\\boldy) = \\Sum_{i = 1}^n \\lp \\frac{y_i - a(x_i;\\boldX,\\boldy)}{1 - \\|\\boldX(\\boldX^T\\boldX)^{-1}\\boldX^T\\|_{ii}}\\rp^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Информационный критерий Акаике<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian information critertion<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='criterions'></a>\n",
    "### Критерии<sup>[toc](#toc)</sup>\n",
    "\n",
    "Рассмотрим несколько критериев для оценивания модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Criterion(object):\n",
    "    def initialize(self, X, y):\n",
    "        self._check_Xy_pair(X, y)\n",
    "        self.X = X; self.y = y\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = find_weights(X, y)\n",
    "        self.sigma2 = np.sum((y - np.dot(X, self.weights))**2) / (n_samples - n_features)\n",
    "        self.sigma = np.sqrt(self.sigma2)\n",
    "        return self\n",
    "\n",
    "    def _check_Xy_pair(self, X, y):\n",
    "        assert isinstance(X, np.ndarray)\n",
    "        assert isinstance(y, np.ndarray)\n",
    "        assert X.ndim == 2\n",
    "        assert y.ndim == 1\n",
    "        assert X.shape[0] == y.shape[0]\n",
    "\n",
    "    def __call__(self, indices):\n",
    "        assert False, \"Not implmented\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Criterion'\n",
    "\n",
    "class CriterionCp(Criterion):\n",
    "    def __call__(self, indices):\n",
    "        X = self.X[:, indices]\n",
    "        n_samples, n_features = X.shape\n",
    "        weights = find_weights(X, self.y)\n",
    "        return (np.sum((np.dot(X, weights) - self.y)**2) + 2 * n_features * self.sigma2) / n_samples\n",
    "    def __repr__(self):\n",
    "        return 'Cp'\n",
    "\n",
    "class CriterionLOO(Criterion):\n",
    "    def __call__(self, indices):\n",
    "        X = self.X[:, indices]\n",
    "        weights = find_weights(X, self.y)\n",
    "        n_samples, n_features = X.shape\n",
    "        U = np.dot(np.dot(X, np.linalg.inv(np.dot(X.T, X))), X.T)\n",
    "        U = U[np.arange(n_samples), np.arange(n_samples)]\n",
    "        return np.sum(((self.y - np.dot(X, weights)) / (1 - U)) ** 2) / n_samples\n",
    "    def __repr__(self):\n",
    "        return 'LOO'\n",
    "\n",
    "class CriterionCV(Criterion):\n",
    "    def __init__(self, n_folds=5, random_state=1):\n",
    "        self.n_folds = n_folds\n",
    "        self.random_state = random_state\n",
    "    def __call__(self, indices):\n",
    "        X = self.X[:, indices]\n",
    "        n_samples, n_features = X.shape\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=self.random_state)\n",
    "        R_CV = 0\n",
    "        for tr_indices, ts_indices in kfold.split(X):\n",
    "            X_tr = X[tr_indices]; y_tr = self.y[tr_indices]\n",
    "            X_ts = X[ts_indices]; y_ts = self.y[ts_indices]\n",
    "            weights = find_weights(X_tr, y_tr)\n",
    "            R_CV += np.sum((y_ts - np.dot(X_ts, weights)) ** 2)\n",
    "        return R_CV / n_samples\n",
    "    def __repr__(self):\n",
    "        return 'CV' + str(self.n_folds)\n",
    "    \n",
    "class CriterionTest(Criterion):\n",
    "    def __init__(self, X_test, y_test):\n",
    "        self.X_test = np.array(X_test)\n",
    "        self.y_test = np.array(y_test)\n",
    "    def __call__(self, indices):\n",
    "        X = self.X[:, indices]\n",
    "        n_samples, n_features = X.shape\n",
    "        weights = find_weights(X, self.y)\n",
    "        return np.sum((self.y_test - np.dot(self.X_test[:, indices], weights))**2) / self.X_test.shape[0]\n",
    "    def __repr__(self):\n",
    "        return 'Test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model_search'></a>\n",
    "### Классы FullSearch и GreedySearch [[toc]](#toc) [[up]](#model_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullSearch:\n",
    "    def __init__(self, X, y, criterion, X_test=None, y_test=None, feature_names=None, verbose=False):\n",
    "        criterion.initialize(X, y)\n",
    "        self.criterion = criterion\n",
    "        self.X = X; self.y = y\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "        if feature_names is None:\n",
    "            feature_names = list(range(self.n_features))\n",
    "        assert len(feature_names) == self.n_features\n",
    "        self.feature_names = feature_names\n",
    "        self.fname2ind = {name:i for i, name in enumerate(self.feature_names)}\n",
    "        self.ind2fname = {i:name for i, name in enumerate(self.feature_names)}\n",
    "\n",
    "        if not ((X_test is None) | (y_test is None)):\n",
    "            self.criterion._check_Xy_pair(X_test, y_test)\n",
    "            assert self.X.shape[1] == self.n_features\n",
    "            self.X_test = X_test\n",
    "            self.y_test = y_test\n",
    "        else:\n",
    "            self.X_test = None\n",
    "            self.y_test = None\n",
    "\n",
    "    def find_best_subset(self):\n",
    "        best_value = np.inf\n",
    "        best_subset = []\n",
    "        for n_features in range(1, self.n_features + 1):\n",
    "            for indices in combinations(list(range(self.n_features)), n_features):\n",
    "                criterion_value = self.criterion(indices)\n",
    "                if criterion_value < best_value:\n",
    "                    best_value = criterion_value\n",
    "                    best_subset = indices\n",
    "        feature_names = [self.ind2fname[i] for i in best_subset]\n",
    "        return OrderedDict([('feature_indices', best_subset), \n",
    "               ('feature_names', feature_names), \n",
    "               ('best_value', best_value)])\n",
    "\n",
    "class GreedySearch:\n",
    "    def __init__(self, X, y, criterion, feature_names=None, forward=True, verbose=False):\n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "        self.criterion = criterion.initialize(self.X, self.y)\n",
    "        self.n_samles, self.n_features = self.X.shape\n",
    "        if feature_names is None:\n",
    "            feature_names = list(range(self.n_features))\n",
    "        assert len(feature_names) == self.n_features\n",
    "        self.feature_names = feature_names\n",
    "        self.forward = forward\n",
    "        self.verbose = verbose\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "        self.all_features = set(range(self.n_features))\n",
    "        self._find_sigma()\n",
    "    \n",
    "    def _find_sigma(self):\n",
    "        self.beta = find_weights(self.X, self.y)\n",
    "        self.sigma = np.sqrt(np.sum((self.y - np.dot(self.X, self.beta)) ** 2) / (self.n_samples - self.n_features))\n",
    "           \n",
    "    def __call__(self):\n",
    "        if self.forward:\n",
    "            self.curr_value = np.inf\n",
    "            self.curr_features = set()\n",
    "            while self._forward_step():\n",
    "                pass\n",
    "        else:\n",
    "            self.curr_value = np.inf\n",
    "            self.curr_features = set(range(self.n_features))\n",
    "            while self._backward_step():\n",
    "                pass\n",
    "            \n",
    "        best_subset = sorted(list(self.curr_features))\n",
    "        feature_names = [self.feature_names[i] for i in best_subset]\n",
    "        return OrderedDict([('feature_indices', best_subset), \n",
    "                            ('feature_names', feature_names), \n",
    "                            ('best_value', self.curr_value)])\n",
    "            \n",
    "    def _forward_step(self):\n",
    "        self.not_considered = self.all_features - self.curr_features # Еще не рассморенные признаки\n",
    "        best_feature = -1     \n",
    "        best_value = np.inf\n",
    "        for n_feature in sorted(list(self.not_considered)):\n",
    "            new_features = copy.deepcopy(self.curr_features)\n",
    "            new_features.add(n_feature)\n",
    "            new_features = np.array(sorted(list(new_features)))\n",
    "\n",
    "            value = self.criterion(new_features)\n",
    "            self.print('F_step: new feature set {} gives value = {}'.format(new_features, value))\n",
    "            if value < best_value:\n",
    "                best_value = value\n",
    "                best_feature = n_feature\n",
    "        if best_value < self.curr_value:\n",
    "            self.curr_value = best_value\n",
    "            self.print('F_step: feature {} added to feature set {}\\n'.format(\n",
    "                best_feature, sorted(list(self.curr_features))))\n",
    "            self.curr_features.add(best_feature)\n",
    "            return True\n",
    "        else:\n",
    "            self.print('F_step: maximum reached for feature set {}; current value = {}\\n'.format(\n",
    "                self.curr_features, self.curr_value))\n",
    "            return False\n",
    "    \n",
    "    def _backward_step(self):\n",
    "        best_feature = -1\n",
    "        best_value = np.inf\n",
    "        for n_feature in sorted(list(self.curr_features)):\n",
    "            new_features = copy.deepcopy(self.curr_features)\n",
    "            new_features.remove(n_feature)\n",
    "            new_features = np.array(sorted(list(new_features)))\n",
    "            if len(new_features) == 0:\n",
    "                break\n",
    "            value = self.criterion(new_features)\n",
    "            self.print('B_step: new feature set {} gives value = {}'.format(new_features, value))\n",
    "            if value < best_value:\n",
    "                best_value = value\n",
    "                best_feature = n_feature\n",
    "        if best_value < self.curr_value:\n",
    "            self.curr_value = best_value\n",
    "            self.print('B_step: feature {} removed from feature set {}\\n'.format(\n",
    "                best_feature, sorted(list(self.curr_features))))\n",
    "            self.curr_features.remove(best_feature)\n",
    "            return True\n",
    "        else:\n",
    "            self.print('B_step: maximum reached for feature set {}; current value = {}\\n'.format(\n",
    "                self.curr_features, self.curr_value))\n",
    "            return False\n",
    "        \n",
    "    def print(self, msg):\n",
    "        if self.verbose:\n",
    "            print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model_plot'></a>\n",
    "### Функции для визуализации динамики весов [[toc]](#toc) [[up]](#model_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_path(make_model, alphas, **model_kwargs):\n",
    "    coefs = []\n",
    "    for a in alphas:\n",
    "        model = make_model(alpha=a, **model_kwargs)\n",
    "        model.fit(X, y)\n",
    "        coefs.append(model.coef_)\n",
    "    return np.array(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_path(ax, alphas, Model, **kwargs):\n",
    "    model_name = str(Model())\n",
    "    model_name = model_name[:model_name.find('(')]\n",
    "\n",
    "    coeffs = get_model_path(Model, alphas, **kwargs)\n",
    "\n",
    "    ax.plot(alphas, coeffs)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('regularization parameter')\n",
    "    ax.set_ylabel('weights')\n",
    "    ax.set_title('{} coefficients'.format(model_name))\n",
    "    ax.grid(which='major', linestyle='--', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='diabetes'></a>\n",
    "## Diabetes dataset [[toc]](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "X = np.hstack([X, np.ones((X.shape[0], 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(3, 1, figsize=(9, 16))\n",
    "\n",
    "fit_intercept = False\n",
    "n_alphas = 200\n",
    "alphas = np.logspace(-5, 1, n_alphas)\n",
    "\n",
    "plot_model_path(axarr[0], alphas, linear_model.Ridge, **{'fit_intercept': fit_intercept})\n",
    "\n",
    "plot_model_path(axarr[1], alphas, linear_model.Lasso, **{'fit_intercept': fit_intercept})\n",
    "\n",
    "plot_model_path(axarr[2], alphas, linear_model.ElasticNet, **{'fit_intercept': fit_intercept})\n",
    "\n",
    "tmp_ = plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кросс-валидация  [[toc]](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = linear_model.Lasso(random_state=153, fit_intercept=False)\n",
    "model = linear_model.Ridge(random_state=153, fit_intercept=False)\n",
    "\n",
    "n_alphas = 64\n",
    "alphas = np.logspace(-5, 1, n_alphas)\n",
    "\n",
    "tuned_parameters = [{'alpha': alphas}]\n",
    "n_folds = 3\n",
    "\n",
    "gscv = GridSearchCV(model, tuned_parameters, scoring='neg_mean_squared_error', cv=n_folds, refit=True, iid=True, return_train_score=True)\n",
    "gscv.fit(X_train, y_train)\n",
    "\n",
    "pd.DataFrame(gscv.cv_results_).sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибка и параметры лучшей модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.best_score_, gscv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшая модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = gscv.predict(X_test)\n",
    "print(-np.mean((y_test - pred_test)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Отбор признаков  [[toc]](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape\n",
    "\n",
    "criterions = [CriterionCp(), CriterionLOO(), CriterionCV(5), CriterionCV(10), CriterionTest(X_test, y_test)]\n",
    "for criterion in criterions:\n",
    "    full_searcher = FullSearch(X_train, y_train, criterion, X_test, y_test)\n",
    "    results = full_searcher.find_best_subset()\n",
    "    indices = results['feature_indices']\n",
    "    weights = find_weights(X_train[:,indices], y_train)\n",
    "    print(criterion)\n",
    "    for k, v in results.items():\n",
    "        print('\\t{}: {}'.format(k, v))\n",
    "    print('\\tMSE test: {}'.format(np.mean((np.dot(X_test[:,indices], weights) - y_test)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prostate'></a>\n",
    "## Prostate dataset [[toc]](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data'\n",
    "df = pd.read_csv(url, sep='\\t', header=0, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[df.train == 'T'].drop(['lpsa', 'train'], axis=1).values\n",
    "y_train = df[df.train == 'T']['lpsa'].values\n",
    "\n",
    "X_test = df[df.train == 'F'].drop(['lpsa', 'train'], axis=1).values\n",
    "y_test = df[df.train == 'F']['lpsa'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Полный перебор множеств признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape\n",
    "\n",
    "criterions = [CriterionCp(), CriterionLOO(), CriterionCV(5), CriterionCV(10), CriterionTest(X_test, y_test)]\n",
    "for criterion in criterions:\n",
    "    full_searcher = FullSearch(X_train, y_train, criterion, X_test, y_test)\n",
    "    results = full_searcher.find_best_subset()\n",
    "    indices = results['feature_indices']\n",
    "    weights = find_weights(X_train[:,indices], y_train)\n",
    "    print(criterion)\n",
    "    for k, v in results.items():\n",
    "        print('\\t{}: {}'.format(k, v))\n",
    "    print('\\tMSE test: {}'.format(np.mean((np.dot(X_test[:,indices], weights) - y_test)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Жадный перебор множеств признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "criterions = [CriterionCp(), CriterionLOO(), CriterionCV(5), CriterionCV(10), CriterionTest(X_test, y_test)]\n",
    "for criterion in criterions:\n",
    "    searcher = GreedySearch(X_train, y_train, criterion, forward=True, verbose=verbose)\n",
    "    results = searcher()\n",
    "    best_features = results['feature_indices']\n",
    "    best_value = results['best_value']\n",
    "    weights = find_weights(X_train[:,best_features], y_train)\n",
    "    print(criterion, 'forward', best_features, best_value)\n",
    "    print('\\tMSE test: {}'.format(np.mean((np.dot(X_test[:,best_features], weights) - y_test)**2)))\n",
    "\n",
    "    searcher = GreedySearch(X_train, y_train, criterion, forward=False, verbose=verbose)\n",
    "    results = searcher()\n",
    "    best_features = results['feature_indices']\n",
    "    best_value = results['best_value']\n",
    "    weights = find_weights(X_train[:,best_features], y_train)\n",
    "    weights = find_weights(X_train[:,best_features], y_train)\n",
    "    print(criterion, 'backward', best_features, best_value)\n",
    "    print('\\tMSE test: {}'.format(np.mean((np.dot(X_test[:,best_features], weights) - y_test)**2)))\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
